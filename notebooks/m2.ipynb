{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bd97f2-dc86-4664-a78f-1636f132b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project paths:\n",
      " PROJECT_DIR: C:\\Users\\MYG-D02\\variant-effect-prediction\n",
      " RAW_DIR: C:\\Users\\MYG-D02\\variant-effect-prediction/data/raw\n",
      " PROC_DIR: C:\\Users\\MYG-D02\\variant-effect-prediction/data/processed\n",
      " CLINVAR_RAW: C:\\Users\\MYG-D02\\variant-effect-prediction/data/raw/variant_summary.txt\n",
      " DBSNP_PATH: C:\\Users\\MYG-D02\\variant-effect-prediction/data/raw/GCF_000001405.40\n",
      " GNOMAD_PATH: C:\\Users\\MYG-D02\\variant-effect-prediction/data/raw/ExAC.r1.sites.vep.vcf\n",
      "HAS_PYSAM: True HAS_CYVCF2: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: setup\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = r\"C:\\Users\\MYG-D02\\variant-effect-prediction\"\n",
    "RAW_DIR     = os.path.join(PROJECT_DIR, \"data\", \"raw\")\n",
    "PROC_DIR    = os.path.join(PROJECT_DIR, \"data\", \"processed\")\n",
    "os.makedirs(PROC_DIR, exist_ok=True)\n",
    "\n",
    "CLINVAR_RAW = os.path.join(RAW_DIR, \"variant_summary.txt\")          # or .gz\n",
    "DBSNP_PATH  = os.path.join(RAW_DIR, \"GCF_000001405.40\")             # directory or file\n",
    "GNOMAD_PATH = os.path.join(RAW_DIR, \"ExAC.r1.sites.vep.vcf\")       # or .gz\n",
    "\n",
    "print(\"Project paths:\")\n",
    "print(\" PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\" RAW_DIR:\", RAW_DIR)\n",
    "print(\" PROC_DIR:\", PROC_DIR)\n",
    "print(\" CLINVAR_RAW:\", CLINVAR_RAW)\n",
    "print(\" DBSNP_PATH:\", DBSNP_PATH)\n",
    "print(\" GNOMAD_PATH:\", GNOMAD_PATH)\n",
    "\n",
    "# Try to detect VCF helper libraries\n",
    "HAS_PYSAM = False; HAS_CYVCF2 = False\n",
    "try:\n",
    "    import pysam\n",
    "    HAS_PYSAM = True\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    import cyvcf2\n",
    "    HAS_CYVCF2 = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"HAS_PYSAM:\", HAS_PYSAM, \"HAS_CYVCF2:\", HAS_CYVCF2)\n",
    "\n",
    "# small helper: safe read CSV with gzip detection\n",
    "def read_table_auto(path, **kwargs):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    if path.suffix == \".gz\":\n",
    "        return pd.read_csv(path, compression=\"gzip\", **kwargs)\n",
    "    return pd.read_csv(path, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee07624-bb4f-475a-8673-ae2b23f0234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR exists? True   path: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw\n",
      "\n",
      "Files/dirs in /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw (first 200):\n",
      "  ExAC.r1.sites.vep.vcf (dir)\n",
      "  ExAC_test.vcf \n",
      "  GCF_000001405.40 (dir)\n",
      "  GCF_000001405.40.gz \n",
      "  homo_sapiens_vep_115_GRCh38 (dir)\n",
      "  homo_sapiens_vep_115_GRCh38.tar.gz \n",
      "  variant_summary.txt (dir)\n",
      "  variant_summary.txt.gz \n",
      "\n",
      "Candidate files for ClinVar (top 10):\n",
      "  - /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt\n",
      "  - /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt.gz\n",
      "\n",
      "Selected clinvar candidate: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt\n",
      " Size (MB): 0.0\n",
      " Is dir?: True\n"
     ]
    }
   ],
   "source": [
    "# Cell A: detect ClinVar file in RAW_DIR and show helpful info\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "RAW_DIR = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw\")\n",
    "\n",
    "print(\"RAW_DIR exists?\", RAW_DIR.exists(), \"  path:\", RAW_DIR)\n",
    "if not RAW_DIR.exists(): \n",
    "    raise FileNotFoundError(f\"RAW_DIR not found: {RAW_DIR}\")\n",
    "\n",
    "# list files and directories\n",
    "items = sorted(RAW_DIR.iterdir(), key=lambda p: p.name.lower())\n",
    "print(f\"\\nFiles/dirs in {RAW_DIR} (first 200):\")\n",
    "for p in items[:200]:\n",
    "    print(\" \", p.name, \"(dir)\" if p.is_dir() else \"\")\n",
    "\n",
    "# Candidate names / patterns to look for\n",
    "candidates = []\n",
    "patterns = [\"variant_summary\", \"variant-summary\", \"variant_summary.txt\", \"variant_summary.txt.gz\",\n",
    "            \"variant_summary.txt.gz\", \"variant_summary.txt\", \"variant_summary\", \"ExAC\", \"GCF_000001405.40\"]\n",
    "for p in items:\n",
    "    name = p.name.lower()\n",
    "    if any(pat in name for pat in [\"variant_summary\", \"variant-summary\", \"variant_summary.txt\", \"variant_summary.txt.gz\", \"variant_summary.txt\"]):\n",
    "        candidates.append(p)\n",
    "# if none found, try other large files\n",
    "if not candidates:\n",
    "    for p in items:\n",
    "        if p.suffix.lower() in [\".gz\", \".txt\", \".vcf\", \".vcf.gz\"] or p.is_dir():\n",
    "            candidates.append(p)\n",
    "\n",
    "print(\"\\nCandidate files for ClinVar (top 10):\")\n",
    "for c in candidates[:10]:\n",
    "    print(\"  -\", c)\n",
    "\n",
    "# Auto-pick the most likely ClinVar file if present\n",
    "clinvar_path = None\n",
    "for c in candidates:\n",
    "    if \"variant_summary\" in c.name.lower():\n",
    "        clinvar_path = c\n",
    "        break\n",
    "# otherwise prefer gz over txt\n",
    "if clinvar_path is None:\n",
    "    for c in candidates:\n",
    "        if c.suffix.lower() == \".gz\" and \"variant\" in c.name.lower():\n",
    "            clinvar_path = c\n",
    "            break\n",
    "\n",
    "# Final fallback: first big file > 100MB that looks like the large ClinVar you downloaded\n",
    "if clinvar_path is None:\n",
    "    big_files = [p for p in items if p.is_file() and p.stat().st_size > 100*1024*1024]\n",
    "    if big_files:\n",
    "        clinvar_path = big_files[0]\n",
    "\n",
    "print(\"\\nSelected clinvar candidate:\", clinvar_path)\n",
    "if clinvar_path:\n",
    "    print(\" Size (MB):\", round(clinvar_path.stat().st_size/1024/1024,2))\n",
    "    print(\" Is dir?:\", clinvar_path.is_dir())\n",
    "else:\n",
    "    raise FileNotFoundError(\"No plausible ClinVar file found in RAW_DIR. Please download variant_summary and place it in RAW_DIR or update RAW_DIR path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c353f46-e2e3-4f8e-8793-4a8bd6f89443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR exists? True  -> /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw\n",
      "DIR  ExAC.r1.sites.vep.vcf                                         size=4096\n",
      "DIR  GCF_000001405.40                                              size=4096\n",
      "DIR  homo_sapiens_vep_115_GRCh38                                   size=4096\n",
      "DIR  variant_summary.txt                                           size=4096\n",
      "FILE ExAC_test.vcf                                                 size=665914\n",
      "FILE GCF_000001405.40.gz                                           size=29552227779\n",
      "FILE homo_sapiens_vep_115_GRCh38.tar.gz                            size=25272957721\n",
      "FILE variant_summary.txt.gz                                        size=397000747\n",
      "\n",
      "Target path: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt\n",
      "Exists: True\n",
      "Is file: False\n",
      "Is dir : True\n",
      "\n",
      "Contents of the directory (first 50 items):\n",
      "   variant_summary.txt\n",
      "If you see a .gz or .txt file inside, use that path (print it here):\n",
      " -> candidate file inside: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt/variant_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Cell B1 — quick diagnostics\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "RAW_DIR = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw\")   # adjust if different\n",
    "print(\"RAW_DIR exists?\", RAW_DIR.exists(), \" ->\", RAW_DIR)\n",
    "\n",
    "# list the files & directories in RAW_DIR (show sizes)\n",
    "for p in sorted(RAW_DIR.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower())):\n",
    "    t = \"DIR \" if p.is_dir() else \"FILE\"\n",
    "    try:\n",
    "        size = p.stat().st_size\n",
    "    except Exception:\n",
    "        size = None\n",
    "    print(f\"{t:4} {p.name:60}  size={size}\")\n",
    "\n",
    "# inspect the specific entry you used\n",
    "target = RAW_DIR / \"variant_summary.txt\"\n",
    "print(\"\\nTarget path:\", target)\n",
    "print(\"Exists:\", target.exists())\n",
    "print(\"Is file:\", target.is_file())\n",
    "print(\"Is dir :\", target.is_dir())\n",
    "\n",
    "if target.exists() and target.is_dir():\n",
    "    print(\"\\nContents of the directory (first 50 items):\")\n",
    "    for i, c in enumerate(sorted(target.iterdir(), key=lambda x: x.name)[:50]):\n",
    "        print(\"  \", c.name)\n",
    "    print(\"If you see a .gz or .txt file inside, use that path (print it here):\")\n",
    "    for c in target.iterdir():\n",
    "        if c.suffix in (\".gz\", \".txt\", \".vcf\"):\n",
    "            print(\" -> candidate file inside:\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a45e06-8fb8-438e-92d0-75b05bd90480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using clinvar_path: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt/variant_summary.txt\n",
      "Exists: True Is file: True Is dir: False\n",
      "Detected compression: None\n",
      "Reading ClinVar in chunks from: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/variant_summary.txt/variant_summary.txt\n",
      "Processed chunk 1: found 79525 rows of benign/pathogenic\n",
      "Processed chunk 2: found 45513 rows of benign/pathogenic\n",
      "Processed chunk 3: found 37537 rows of benign/pathogenic\n",
      "Processed chunk 4: found 27752 rows of benign/pathogenic\n",
      "Processed chunk 5: found 26513 rows of benign/pathogenic\n",
      "Processed chunk 6: found 77166 rows of benign/pathogenic\n",
      "Processed chunk 7: found 25280 rows of benign/pathogenic\n",
      "Processed chunk 8: found 15816 rows of benign/pathogenic\n",
      "Processed chunk 9: found 25759 rows of benign/pathogenic\n",
      "Processed chunk 10: found 17811 rows of benign/pathogenic\n",
      "Processed chunk 11: found 121255 rows of benign/pathogenic\n",
      "Processed chunk 12: found 50456 rows of benign/pathogenic\n",
      "Processed chunk 13: found 18278 rows of benign/pathogenic\n",
      "Processed chunk 14: found 14345 rows of benign/pathogenic\n",
      "Processed chunk 15: found 15164 rows of benign/pathogenic\n",
      "Processed chunk 16: found 13625 rows of benign/pathogenic\n",
      "Processed chunk 17: found 14590 rows of benign/pathogenic\n",
      "Processed chunk 18: found 9053 rows of benign/pathogenic\n",
      "Processed chunk 19: found 17708 rows of benign/pathogenic\n",
      "Processed chunk 20: found 6659 rows of benign/pathogenic\n",
      "Processed chunk 21: found 308 rows of benign/pathogenic\n",
      "Processed chunk 22: found 2837 rows of benign/pathogenic\n",
      "Processed chunk 23: found 5238 rows of benign/pathogenic\n",
      "Processed chunk 24: found 13846 rows of benign/pathogenic\n",
      "Processed chunk 25: found 20587 rows of benign/pathogenic\n",
      "Processed chunk 26: found 16684 rows of benign/pathogenic\n",
      "Processed chunk 27: found 11985 rows of benign/pathogenic\n",
      "Processed chunk 28: found 19187 rows of benign/pathogenic\n",
      "Processed chunk 29: found 1491 rows of benign/pathogenic\n",
      "Processed chunk 30: found 11019 rows of benign/pathogenic\n",
      "Processed chunk 31: found 8556 rows of benign/pathogenic\n",
      "Processed chunk 32: found 802 rows of benign/pathogenic\n",
      "Processed chunk 33: found 4832 rows of benign/pathogenic\n",
      "Processed chunk 34: found 14652 rows of benign/pathogenic\n",
      "Processed chunk 35: found 8016 rows of benign/pathogenic\n",
      "Processed chunk 36: found 5487 rows of benign/pathogenic\n",
      "Processed chunk 37: found 628 rows of benign/pathogenic\n",
      "Processed chunk 38: found 4914 rows of benign/pathogenic\n",
      "Processed chunk 39: found 431 rows of benign/pathogenic\n",
      "Processed chunk 40: found 2258 rows of benign/pathogenic\n",
      "Total rows collected: 813563\n",
      "Sample columns: ['#alleleid', 'type', 'name', 'geneid', 'genesymbol', 'hgnc_id', 'clinicalsignificance', 'clinsigsimple', 'lastevaluated', 'rs# (dbsnp)', 'nsv/esv (dbvar)', 'rcvaccession', 'phenotypeids', 'phenotypelist', 'origin', 'originsimple', 'assembly', 'chromosomeaccession', 'chromosome', 'start']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#alleleid</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>geneid</th>\n",
       "      <th>genesymbol</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>clinicalsignificance</th>\n",
       "      <th>clinsigsimple</th>\n",
       "      <th>lastevaluated</th>\n",
       "      <th>rs# (dbsnp)</th>\n",
       "      <th>...</th>\n",
       "      <th>somaticclinicalimpact</th>\n",
       "      <th>somaticclinicalimpactlastevaluated</th>\n",
       "      <th>reviewstatusclinicalimpact</th>\n",
       "      <th>oncogenicity</th>\n",
       "      <th>oncogenicitylastevaluated</th>\n",
       "      <th>reviewstatusoncogenicity</th>\n",
       "      <th>scvsforaggregategermlineclassification</th>\n",
       "      <th>scvsforaggregatesomaticclinicalimpact</th>\n",
       "      <th>scvsforaggregateoncogenicityclassification</th>\n",
       "      <th>clnsig_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15042</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 29, 2010</td>\n",
       "      <td>397704709</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SCV000020156</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>pathogenic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15042</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 29, 2010</td>\n",
       "      <td>397704709</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SCV000020156</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>pathogenic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15044</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_017547.4(FOXRED1):c.694C&gt;T (p.Gln232Ter)</td>\n",
       "      <td>55572</td>\n",
       "      <td>FOXRED1</td>\n",
       "      <td>HGNC:26927</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Aug 17, 2025</td>\n",
       "      <td>267606829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SCV000680696|SCV001363290|SCV002793147|SCV0029...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>pathogenic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15044</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_017547.4(FOXRED1):c.694C&gt;T (p.Gln232Ter)</td>\n",
       "      <td>55572</td>\n",
       "      <td>FOXRED1</td>\n",
       "      <td>HGNC:26927</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Aug 17, 2025</td>\n",
       "      <td>267606829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SCV000680696|SCV001363290|SCV002793147|SCV0029...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>pathogenic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   #alleleid                       type  \\\n",
       "0      15042                   Deletion   \n",
       "1      15042                   Deletion   \n",
       "2      15044  single nucleotide variant   \n",
       "3      15044  single nucleotide variant   \n",
       "\n",
       "                                             name  geneid genesymbol  \\\n",
       "0  NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)    9907      AP5Z1   \n",
       "1  NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)    9907      AP5Z1   \n",
       "2     NM_017547.4(FOXRED1):c.694C>T (p.Gln232Ter)   55572    FOXRED1   \n",
       "3     NM_017547.4(FOXRED1):c.694C>T (p.Gln232Ter)   55572    FOXRED1   \n",
       "\n",
       "      hgnc_id clinicalsignificance  clinsigsimple lastevaluated  rs# (dbsnp)  \\\n",
       "0  HGNC:22197           Pathogenic              1  Jun 29, 2010    397704709   \n",
       "1  HGNC:22197           Pathogenic              1  Jun 29, 2010    397704709   \n",
       "2  HGNC:26927           Pathogenic              1  Aug 17, 2025    267606829   \n",
       "3  HGNC:26927           Pathogenic              1  Aug 17, 2025    267606829   \n",
       "\n",
       "   ... somaticclinicalimpact somaticclinicalimpactlastevaluated  \\\n",
       "0  ...                     -                                  -   \n",
       "1  ...                     -                                  -   \n",
       "2  ...                     -                                  -   \n",
       "3  ...                     -                                  -   \n",
       "\n",
       "  reviewstatusclinicalimpact oncogenicity oncogenicitylastevaluated  \\\n",
       "0                          -            -                         -   \n",
       "1                          -            -                         -   \n",
       "2                          -            -                         -   \n",
       "3                          -            -                         -   \n",
       "\n",
       "  reviewstatusoncogenicity             scvsforaggregategermlineclassification  \\\n",
       "0                        -                                       SCV000020156   \n",
       "1                        -                                       SCV000020156   \n",
       "2                        -  SCV000680696|SCV001363290|SCV002793147|SCV0029...   \n",
       "3                        -  SCV000680696|SCV001363290|SCV002793147|SCV0029...   \n",
       "\n",
       "  scvsforaggregatesomaticclinicalimpact  \\\n",
       "0                                     -   \n",
       "1                                     -   \n",
       "2                                     -   \n",
       "3                                     -   \n",
       "\n",
       "  scvsforaggregateoncogenicityclassification  clnsig_simple  \n",
       "0                                          -     pathogenic  \n",
       "1                                          -     pathogenic  \n",
       "2                                          -     pathogenic  \n",
       "3                                          -     pathogenic  \n",
       "\n",
       "[4 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABCA4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f2674d-8df4-4fcb-b2bc-15b6c41a39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept columns: ['variationid', 'gene', 'chr', 'pos', 'ref', 'alt', 'name', 'clinicalsignificance', 'rsid']\n",
      "Label counts (incl. None):\n",
      "label\n",
      "0    425402\n",
      "1    388161\n",
      "Name: count, dtype: int64\n",
      "Saved: clinvar_stage1_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — standardize & label\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    df  # if exists\n",
    "except NameError:\n",
    "    proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "   \n",
    "    candidate = proc_dir / \"clinvar_filtered_labels.csv\"\n",
    "    if candidate.exists():\n",
    "        df = pd.read_csv(candidate, low_memory=False)\n",
    "    else:\n",
    "        raise RuntimeError(\"No `df` found in memory and no clinvar_filtered_labels.csv detected. Load ClinVar first.\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# Map common column names to canonical names we will use\n",
    "col_map = {}\n",
    "# try to detect fields\n",
    "if \"chromosome\" in df.columns:\n",
    "    col_map[\"chromosome\"] = \"chr\"\n",
    "if \"start\" in df.columns:\n",
    "    col_map[\"start\"] = \"pos\"\n",
    "if \"referenceallele\" in df.columns:\n",
    "    col_map[\"referenceallele\"] = \"ref\"\n",
    "if \"alternateallele\" in df.columns:\n",
    "    col_map[\"alternateallele\"] = \"alt\"\n",
    "if \"rs# (dbsnp)\" in df.columns:\n",
    "    df = df.rename(columns={\"rs# (dbsnp)\": \"rsid\"})\n",
    "\n",
    "rename_map = {\n",
    "    \"genesymbol\": \"gene\",\n",
    "    \"clinicalsignificance\": \"clinicalsignificance\",\n",
    "}\n",
    "df = df.rename(columns={**col_map, **rename_map})\n",
    "\n",
    "# build minimal df with canonical columns (some may be missing; keep what exists)\n",
    "keep = []\n",
    "for k in [\"variationid\",\"gene\",\"chr\",\"pos\",\"ref\",\"alt\",\"name\",\"clinicalsignificance\",\"rsid\"]:\n",
    "    if k in df.columns:\n",
    "        keep.append(k)\n",
    "\n",
    "df = df[keep].copy()\n",
    "\n",
    "# create simple label: 'pathogenic'->1, 'benign'->0\n",
    "def simplify_label(x):\n",
    "    if pd.isna(x): \n",
    "        return None\n",
    "    s = str(x).lower()\n",
    "    # clinicalSignificance might be 'Pathogenic/likely pathogenic' etc.\n",
    "    # We take the first semicolon-split or comma-split token when needed\n",
    "    s0 = s.split(\";\")[0].split(\",\")[0].strip()\n",
    "    if \"pathogenic\" in s0:\n",
    "        return 1\n",
    "    if \"benign\" in s0:\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "df[\"label\"] = df[\"clinicalsignificance\"].apply(simplify_label)\n",
    "\n",
    "print(\"Kept columns:\", keep)\n",
    "print(\"Label counts (incl. None):\")\n",
    "print(df[\"label\"].value_counts(dropna=False))\n",
    "# Save a checkpoint\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "proc_dir.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(proc_dir / \"clinvar_stage1_standardized.csv\", index=False)\n",
    "print(\"Saved: clinvar_stage1_standardized.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72b4d64-fc63-421f-be1f-1698ffec686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dedup: 813563 -> after dedup: 809642\n",
      "Rows after removing missing coords: 809642\n",
      "Filled ref/alt from name for 490411 rows (simple SNV cases).\n",
      "Saved clinvar_stage1_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — drop duplicates, basic filtering, and try to fill ref/alt from name\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# reload to be safe\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "df = pd.read_csv(proc_dir / \"clinvar_stage1_standardized.csv\", low_memory=False)\n",
    "\n",
    "before = len(df)\n",
    "# drop exact duplicates by major identifying fields\n",
    "id_cols = [c for c in [\"variationid\",\"gene\",\"chr\",\"pos\",\"ref\",\"alt\",\"name\"] if c in df.columns]\n",
    "df = df.drop_duplicates(subset=id_cols)\n",
    "print(f\"Rows before dedup: {before} -> after dedup: {len(df)}\")\n",
    "\n",
    "# remove rows missing chromosome or position\n",
    "mask_coords = df[\"chr\"].notnull() & df[\"pos\"].notnull()\n",
    "df = df[mask_coords].copy()\n",
    "print(\"Rows after removing missing coords:\", len(df))\n",
    "\n",
    "# helper to extract ref/alt from name when pattern like c.1144C>T exists\n",
    "def extract_ref_alt_from_name(name):\n",
    "    if pd.isna(name): \n",
    "        return (None, None)\n",
    "    s = str(name)\n",
    "    m = re.search(r\"c\\.[0-9_+-]*([ACGT])>([ACGT])\", s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return (m.group(1).upper(), m.group(2).upper())\n",
    "    # sometimes the canonical is in parentheses like (p.Gln382Ter) — we don't get ref/alt from protein-level\n",
    "    return (None, None)\n",
    "\n",
    "# only attempt fill where ref or alt is missing (NaN or 'na' or '')\n",
    "def is_missing_val(x):\n",
    "    if pd.isna(x): return True\n",
    "    s = str(x).strip().lower()\n",
    "    return s in (\"\", \"na\", \"n/a\", \"none\", \".\")\n",
    "    \n",
    "fill_count = 0\n",
    "for i, row in df.loc[df.apply(lambda r: is_missing_val(r.get(\"ref\")) or is_missing_val(r.get(\"alt\")), axis=1)].iterrows():\n",
    "    ref_from_name, alt_from_name = extract_ref_alt_from_name(row.get(\"name\", \"\"))\n",
    "    if ref_from_name and alt_from_name:\n",
    "        df.at[i, \"ref\"] = ref_from_name\n",
    "        df.at[i, \"alt\"] = alt_from_name\n",
    "        fill_count += 1\n",
    "\n",
    "print(\"Filled ref/alt from name for\", fill_count, \"rows (simple SNV cases).\")\n",
    "\n",
    "# Save stage1 cleaned\n",
    "df.to_csv(proc_dir / \"clinvar_stage1_cleaned.csv\", index=False)\n",
    "print(\"Saved clinvar_stage1_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d7dec2-e573-4739-8889-b09a67dc4c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed/clinvar_stage1_cleaned.csv\n",
      "Initial shape: (809642, 10)\n",
      "Columns available: ['variationid', 'gene', 'chr', 'pos', 'ref', 'alt', 'name', 'clinicalsignificance', 'rsid', 'label']\n",
      "Total rows: 809642\n",
      "Non-null counts:\n",
      "cdna              758597\n",
      "protein_change    466458\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cdna</th>\n",
       "      <th>protein_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>c.1413_1426del</td>\n",
       "      <td>p.Leu473fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>c.1413_1426del</td>\n",
       "      <td>p.Leu473fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NM_017547.4(FOXRED1):c.694C&gt;T (p.Gln232Ter)</td>\n",
       "      <td>c.694C&gt;T</td>\n",
       "      <td>p.Gln232Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NM_017547.4(FOXRED1):c.694C&gt;T (p.Gln232Ter)</td>\n",
       "      <td>c.694C&gt;T</td>\n",
       "      <td>p.Gln232Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NM_000410.4(HFE):c.892+48G&gt;A</td>\n",
       "      <td>c.892+48G&gt;A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NM_000410.4(HFE):c.892+48G&gt;A</td>\n",
       "      <td>c.892+48G&gt;A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NM_000410.4(HFE):c.989G&gt;T (p.Arg330Met)</td>\n",
       "      <td>c.989G&gt;T</td>\n",
       "      <td>p.Arg330Met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NM_000410.4(HFE):c.989G&gt;T (p.Arg330Met)</td>\n",
       "      <td>c.989G&gt;T</td>\n",
       "      <td>p.Arg330Met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NM_020779.4(WDR35):c.25-2A&gt;G</td>\n",
       "      <td>c.25-2A&gt;G</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NM_020779.4(WDR35):c.25-2A&gt;G</td>\n",
       "      <td>c.25-2A&gt;G</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NM_020779.4(WDR35):c.1844A&gt;G (p.Glu615Gly)</td>\n",
       "      <td>c.1844A&gt;G</td>\n",
       "      <td>p.Glu615Gly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NM_020779.4(WDR35):c.1844A&gt;G (p.Glu615Gly)</td>\n",
       "      <td>c.1844A&gt;G</td>\n",
       "      <td>p.Glu615Gly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name            cdna  \\\n",
       "0   NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)  c.1413_1426del   \n",
       "1   NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)  c.1413_1426del   \n",
       "2      NM_017547.4(FOXRED1):c.694C>T (p.Gln232Ter)        c.694C>T   \n",
       "3      NM_017547.4(FOXRED1):c.694C>T (p.Gln232Ter)        c.694C>T   \n",
       "4                     NM_000410.4(HFE):c.892+48G>A     c.892+48G>A   \n",
       "5                     NM_000410.4(HFE):c.892+48G>A     c.892+48G>A   \n",
       "6          NM_000410.4(HFE):c.989G>T (p.Arg330Met)        c.989G>T   \n",
       "7          NM_000410.4(HFE):c.989G>T (p.Arg330Met)        c.989G>T   \n",
       "8                     NM_020779.4(WDR35):c.25-2A>G       c.25-2A>G   \n",
       "9                     NM_020779.4(WDR35):c.25-2A>G       c.25-2A>G   \n",
       "10      NM_020779.4(WDR35):c.1844A>G (p.Glu615Gly)       c.1844A>G   \n",
       "11      NM_020779.4(WDR35):c.1844A>G (p.Glu615Gly)       c.1844A>G   \n",
       "\n",
       "   protein_change  \n",
       "0      p.Leu473fs  \n",
       "1      p.Leu473fs  \n",
       "2     p.Gln232Ter  \n",
       "3     p.Gln232Ter  \n",
       "4            None  \n",
       "5            None  \n",
       "6     p.Arg330Met  \n",
       "7     p.Arg330Met  \n",
       "8            None  \n",
       "9            None  \n",
       "10    p.Glu615Gly  \n",
       "11    p.Glu615Gly  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed file to: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed/clinvar_stage2_parsed_name.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (fixed) — parse `name` for c. and p. tokens and create `cdna` + `protein_change`\n",
    "# Why: many ClinVar entries store the nucleotide/protein change inside the \"name\" field\n",
    "# (e.g. \"NM_017547.4(...):c.694C>T (p.Gln232Ter)\"). We extract those tokens so later cells\n",
    "# can parse amino-acid changes (BLOSUM/hydropathy/etc).\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "infile = proc_dir / \"clinvar_stage1_cleaned.csv\"\n",
    "if not infile.exists():\n",
    "    raise FileNotFoundError(f\"Input file not found: {infile}\\nMake sure you ran the previous cells and saved clinvar_stage1_cleaned.csv\")\n",
    "\n",
    "# load (low_memory False avoids some warnings for mixed dtypes)\n",
    "df = pd.read_csv(infile, low_memory=False)\n",
    "print(\"Loaded:\", infile)\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Columns available:\", df.columns.tolist()[:30])\n",
    "\n",
    "# parsing function: returns dict with cdna (c.xxx) and protein_change (p.xxx) or None\n",
    "def parse_name_for_cdna_protein(name):\n",
    "    # return dict to make conversion to DataFrame simpler\n",
    "    if pd.isna(name) or str(name).strip() == \"\":\n",
    "        return {\"cdna\": None, \"protein_change\": None}\n",
    "    s = str(name)\n",
    "    # cdna: look for substring starting with 'c.' up to whitespace or punctuation\n",
    "    cdna_m = re.search(r\"(c\\.[A-Za-z0-9_+\\->\\*]+)\", s)\n",
    "    # protein: look for 'p.' token like p.Gln382Ter or p.R72H; we allow parentheses and punctuation\n",
    "    prot_m = re.search(r\"(p\\.[A-Za-z0-9\\*\\._]+)\", s)\n",
    "    return {\"cdna\": cdna_m.group(1) if cdna_m else None,\n",
    "            \"protein_change\": prot_m.group(1) if prot_m else None}\n",
    "\n",
    "# Apply parsing to the 'name' column and expand results into new columns\n",
    "parsed = df[\"name\"].apply(parse_name_for_cdna_protein).apply(pd.Series)\n",
    "df[\"cdna\"] = parsed[\"cdna\"]\n",
    "df[\"protein_change\"] = parsed[\"protein_change\"]\n",
    "\n",
    "# Diagnostics\n",
    "print(\"Total rows:\", len(df))\n",
    "print(\"Non-null counts:\")\n",
    "print(df[[\"cdna\",\"protein_change\"]].notnull().sum())\n",
    "\n",
    "# Show examples for visual check\n",
    "display(df[[\"name\",\"cdna\",\"protein_change\"]].head(12))\n",
    "\n",
    "# Save the result to avoid re-running parsing later; overwrite is ok\n",
    "outpath = proc_dir / \"clinvar_stage2_parsed_name.csv\"\n",
    "df.to_csv(outpath, index=False)\n",
    "print(\"Saved parsed file to:\", outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886d4c24-93d8-4c3d-bedd-91e17b8957b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA parse counts (non-null): {'ref_aa': 206933, 'alt_aa': 203377}\n",
      "Saved clinvar_stage2_aa.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — protein token -> ref_aa, pos_aa, alt_aa\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "three_to_one = {\n",
    "    'Ala':'A','Arg':'R','Asn':'N','Asp':'D','Cys':'C',\n",
    "    'Gln':'Q','Glu':'E','Gly':'G','His':'H','Ile':'I',\n",
    "    'Leu':'L','Lys':'K','Met':'M','Phe':'F','Pro':'P',\n",
    "    'Ser':'S','Thr':'T','Trp':'W','Tyr':'Y','Val':'V',\n",
    "    'Ter':'*', 'Stop':'*'\n",
    "}\n",
    "\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "df = pd.read_csv(proc_dir / \"clinvar_stage2_parsed_name.csv\", low_memory=False)\n",
    "\n",
    "def parse_protein_token(p):\n",
    "    if pd.isna(p): return pd.Series({\"ref_aa\": None, \"pos_aa\": None, \"alt_aa\": None})\n",
    "    s = str(p).strip()\n",
    "    # try 3-letter pattern: p.Gln382Ter or p.Gln382Arg\n",
    "    m = re.match(r\"p\\.([A-Za-z]{3})(\\d+)([A-Za-z]{3}|\\*)\", s)\n",
    "    if m:\n",
    "        ref3, pos, alt3 = m.groups()\n",
    "        ref1 = three_to_one.get(ref3.capitalize(), None)\n",
    "        alt1 = three_to_one.get(alt3.capitalize(), None) if alt3 != \"*\" else \"*\"\n",
    "        return pd.Series({\"ref_aa\": ref1, \"pos_aa\": int(pos), \"alt_aa\": alt1})\n",
    "    # fallback 1-letter like p.R72H\n",
    "    m2 = re.match(r\"p\\.([A-Za-z])(\\d+)([A-Za-z]|\\*)\", s)\n",
    "    if m2:\n",
    "        ref1, pos, alt1 = m2.groups()\n",
    "        return pd.Series({\"ref_aa\": ref1.upper(), \"pos_aa\": int(pos), \"alt_aa\": alt1.upper()})\n",
    "    return pd.Series({\"ref_aa\": None, \"pos_aa\": None, \"alt_aa\": None})\n",
    "\n",
    "parsed_aa = df[\"protein_change\"].apply(parse_protein_token)\n",
    "df[\"ref_aa\"] = parsed_aa[\"ref_aa\"]\n",
    "df[\"pos_aa\"] = parsed_aa[\"pos_aa\"]\n",
    "df[\"alt_aa\"] = parsed_aa[\"alt_aa\"]\n",
    "\n",
    "print(\"AA parse counts (non-null):\", df[[\"ref_aa\",\"alt_aa\"]].notnull().sum().to_dict())\n",
    "df[[\"name\",\"protein_change\",\"ref_aa\",\"pos_aa\",\"alt_aa\"]].head(8)\n",
    "\n",
    "df.to_csv(proc_dir / \"clinvar_stage2_aa.csv\", index=False)\n",
    "print(\"Saved clinvar_stage2_aa.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f900c9-b510-4724-a7f4-ee94c2ae590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biopython BLOSUM not found — using fallback scoring.\n",
      "Computed feature sample counts:\n",
      "blosum62_raw       809642\n",
      "hydropathy_diff    203377\n",
      "is_stop            809642\n",
      "dtype: int64\n",
      "Saved clinvar_stage3_features_basic.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — compute blosum62_raw, hydropathy_diff, is_stop\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "df = pd.read_csv(proc_dir / \"clinvar_stage2_aa.csv\", low_memory=False)\n",
    "\n",
    "# hydropathy scale (Kyte-Doolittle)\n",
    "hydro = {'A':1.8,'R':-4.5,'N':-3.5,'D':-3.5,'C':2.5,'Q':-3.5,'E':-3.5,'G':-0.4,\n",
    "         'H':-3.2,'I':4.5,'L':3.8,'K':-3.9,'M':1.9,'F':2.8,'P':-1.6,'S':-0.8,\n",
    "         'T':-0.7,'W':-0.9,'Y':-1.3,'V':4.2,'*':0}\n",
    "\n",
    "# BLOSUM\n",
    "try:\n",
    "    from Bio.SubsMat.MatrixInfo import blosum62\n",
    "    def blosum_score(a,b):\n",
    "        if a is None or b is None: return None\n",
    "        if a == '*' or b == '*':  # treat stop specially\n",
    "            return -4\n",
    "        pair = (a,b)\n",
    "        if pair in blosum62:\n",
    "            return blosum62[pair]\n",
    "        if (b,a) in blosum62:\n",
    "            return blosum62[(b,a)]\n",
    "        return -1\n",
    "    print(\"Using Biopython blosum62.\")\n",
    "except Exception:\n",
    "    # fallback simple scoring\n",
    "    def blosum_score(a,b):\n",
    "        if a is None or b is None: return None\n",
    "        if a == b: return 4\n",
    "        if a == '*' or b == '*': return -4\n",
    "        return -1\n",
    "    print(\"Biopython BLOSUM not found — using fallback scoring.\")\n",
    "\n",
    "def safe_hydro(a):\n",
    "    if pd.isna(a): return None\n",
    "    return hydro.get(str(a).upper(), None)\n",
    "\n",
    "# compute columns\n",
    "df[\"blosum62_raw\"] = df.apply(lambda r: blosum_score(r[\"ref_aa\"], r[\"alt_aa\"]), axis=1)\n",
    "df[\"hydropathy_diff\"] = df.apply(lambda r: \n",
    "                                 (safe_hydro(r[\"alt_aa\"]) - safe_hydro(r[\"ref_aa\"])) \n",
    "                                 if (safe_hydro(r[\"alt_aa\"]) is not None and safe_hydro(r[\"ref_aa\"]) is not None) else None, axis=1)\n",
    "df[\"is_stop\"] = df[\"alt_aa\"].apply(lambda x: 1 if str(x) == \"*\" else 0)\n",
    "\n",
    "print(\"Computed feature sample counts:\")\n",
    "print(df[[\"blosum62_raw\",\"hydropathy_diff\",\"is_stop\"]].notnull().sum())\n",
    "\n",
    "df.to_csv(proc_dir / \"clinvar_stage3_features_basic.csv\", index=False)\n",
    "print(\"Saved clinvar_stage3_features_basic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539c3543-9f31-4901-bfa8-df173531625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ExAC path: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/ExAC.r1.sites.vep.vcf/ExAC.r1.sites.vep.vcf | exists: True\n",
      "Loaded ML-stage df shape: (809642, 18)\n",
      "Unique variant keys to match: 777857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse_info] INFO 'HOM_CONSANGUINEOUS' is not defined in the header, assuming Type=String\n",
      "[W::vcf_parse_filter] FILTER 'AC_Adj0_Filter' is not defined in the header\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 9362318 VCF records. Matched AF entries: 53468\n",
      "Filled allele_freq for 53474 rows out of 809642\n",
      "Saved merged file to: /mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed/clinvar_stage3_with_af.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 (fixed, robust, memory-friendly) — merge ExAC AF into your clinvar stage3 file\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "proc_dir = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/processed\")\n",
    "raw_exac_path = Path(\"/mnt/c/Users/MYG-D02/variant-effect-prediction/data/raw/ExAC.r1.sites.vep.vcf\")  # file or directory\n",
    "\n",
    "# ---- sanity checks ----\n",
    "if not proc_dir.exists():\n",
    "    raise FileNotFoundError(f\"Processed directory not found: {proc_dir}\")\n",
    "\n",
    "# auto-detect real VCF file if a directory was given\n",
    "if raw_exac_path.is_dir():\n",
    "    # prefer .vcf.gz, then .vcf\n",
    "    candidates = sorted(raw_exac_path.glob(\"**/*.vcf*\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No .vcf or .vcf.gz found inside directory: {raw_exac_path}\")\n",
    "    exac_path = candidates[0]\n",
    "else:\n",
    "    exac_path = raw_exac_path\n",
    "\n",
    "print(\"Using ExAC path:\", exac_path, \"| exists:\", exac_path.exists())\n",
    "\n",
    "# import pysam (helpful error if not installed)\n",
    "try:\n",
    "    import pysam\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"pysam is required but not importable in this environment. Install pysam and re-run. Error: \" + str(e))\n",
    "\n",
    "# load the dataframe we want to enrich\n",
    "ml_input = proc_dir / \"clinvar_stage3_features_basic.csv\"\n",
    "if not ml_input.exists():\n",
    "    raise FileNotFoundError(f\"Expected input CSV not found: {ml_input}\\nMake sure previous stage saved this file.\")\n",
    "df = pd.read_csv(ml_input, low_memory=False)\n",
    "print(\"Loaded ML-stage df shape:\", df.shape)\n",
    "\n",
    "# ensure the columns exist\n",
    "for c in (\"chr\",\"pos\",\"ref\",\"alt\"):\n",
    "    if c not in df.columns:\n",
    "        raise KeyError(f\"Required column missing from dataframe: {c}\")\n",
    "\n",
    "# prepare target keys (normalized)\n",
    "def key_from_row(r):\n",
    "    return (str(r[\"chr\"]).replace(\"chr\",\"\").strip(), int(r[\"pos\"]), str(r[\"ref\"]), str(r[\"alt\"]))\n",
    "\n",
    "want_keys = set()\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        want_keys.add(key_from_row(row))\n",
    "    except Exception:\n",
    "        continue\n",
    "print(\"Unique variant keys to match:\", len(want_keys))\n",
    "\n",
    "# initialize allele_freq column\n",
    "if \"allele_freq\" not in df.columns:\n",
    "    df[\"allele_freq\"] = pd.NA\n",
    "else:\n",
    "    df[\"allele_freq\"] = df[\"allele_freq\"].fillna(pd.NA)\n",
    "\n",
    "# iterate VCF and only record AFs for keys we care about\n",
    "af_map = {}\n",
    "count_scanned = 0\n",
    "count_matched = 0\n",
    "\n",
    "open_path = str(exac_path)\n",
    "try:\n",
    "    vcf = pysam.VariantFile(open_path)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to open VCF with pysam: {open_path}\\nError: {e}\")\n",
    "\n",
    "for rec in vcf:\n",
    "    count_scanned += 1\n",
    "    chrom = rec.chrom.replace(\"chr\",\"\").strip()\n",
    "    pos = rec.pos\n",
    "    ref = rec.ref\n",
    "    alts = rec.alts or []\n",
    "    # AF in VCF INFO can be: AF (list) or missing. Try canonical 'AF' first.\n",
    "    info_af = rec.info.get(\"AF\") or rec.info.get(\"af\") or None\n",
    "\n",
    "    # if INFO AF not present, try common alternate fields (some VCFs use different tags)\n",
    "    # we will treat absence like None and skip storing AF for those entries\n",
    "    if info_af is None:\n",
    "        # optionally try other fields e.g. 'gnomAD_AF' etc. (customize if needed)\n",
    "        # info_af = rec.info.get(\"gnomad_AF\") or rec.info.get(\"GNOMAD_AF\")\n",
    "        info_af = None\n",
    "\n",
    "    # normal handling: zip alts with provided AFs (if AF is a single number for multiallelic, treat as list)\n",
    "    if info_af is not None:\n",
    "        # make it list-like\n",
    "        if isinstance(info_af, (float, int)):\n",
    "            af_list = [float(info_af)] + [None]*(len(alts)-1)\n",
    "        else:\n",
    "            af_list = list(info_af)\n",
    "    else:\n",
    "        af_list = [None]*len(alts)\n",
    "\n",
    "    for alt, af_val in zip(alts, af_list):\n",
    "        key = (chrom, pos, ref, alt)\n",
    "        if key in want_keys:\n",
    "            # convert to float if possible\n",
    "            try:\n",
    "                af_float = float(af_val) if af_val is not None else None\n",
    "            except Exception:\n",
    "                af_float = None\n",
    "            af_map[key] = af_float\n",
    "            count_matched += 1\n",
    "\n",
    "# report\n",
    "print(f\"Scanned {count_scanned} VCF records. Matched AF entries: {len(af_map)}\")\n",
    "\n",
    "# fill dataframe from map (fast single-pass)\n",
    "filled = 0\n",
    "for i, row in df.iterrows():\n",
    "    key = key_from_row(row)\n",
    "    af = af_map.get(key, None)\n",
    "    if af is not None:\n",
    "        df.at[i, \"allele_freq\"] = af\n",
    "        filled += 1\n",
    "\n",
    "print(\"Filled allele_freq for\", filled, \"rows out of\", len(df))\n",
    "\n",
    "# save output\n",
    "outpath = proc_dir / \"clinvar_stage3_with_af.csv\"\n",
    "df.to_csv(outpath, index=False)\n",
    "print(\"Saved merged file to:\", outpath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (varpred)",
   "language": "python",
   "name": "varpred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
